# ğŸ›¡ï¸ Shield AI - Real-Time Cyberbullying Detection

A Flask-based web application that uses an LSTM deep learning model to detect cyberbullying in real-time based on user-submitted text.

## ğŸš€ Features

- ğŸ” Detects whether a message contains cyberbullying or not.
- âœ… Shows confidence score for each prediction.
- ğŸ“£ Allows anonymous reporting of flagged messages.
- âœ¨ Clean, simple HTML frontend.
- ğŸ§  Trained using LSTM with preprocessed and tokenized text data.

## ğŸ“‚ Project Structure
cyber/
â”œâ”€â”€ app.py # Flask backend
â”œâ”€â”€ lstm_bully_detector.keras # Trained LSTM model
â”œâ”€â”€ tokenizer.pickle # Tokenizer used during training
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Frontend HTML page
â”œâ”€â”€ reports.txt # Stores reported messages
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation

## ğŸ§ª How to Run

1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/cyberbullying-detection.git
   cd cyberbullying-detection
2. Create a virtual environment:
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
3. Install requirements:
pip install -r requirements.txt
4. Run the app:
python app.py
5. Open in browser:
http://127.0.0.1:5000/
##Future Ideas
Add login for moderators
Create a dashboard to review reports
Add charts for cyberbullying trends
